import tushare as ts
import os
TUSHARE_TOKEN = os.getenv('TS_TOKEN')
pro = ts.pro_api(TUSHARE_TOKEN)
import pandas as pd
# 设置要获取的日期
TARGET_DATE = '2023-12-29'

# ==================== 主程序 ====================
def main():
    print("正在获取沪深300成分股数据...")
    
    # 2. 获取成分股权重数据
    # 处理日期格式
    trade_date = TARGET_DATE.replace('-', '') if '-' in TARGET_DATE else TARGET_DATE
    
    weights_df = pro.index_weight(
        index_code='000300.SH',
        trade_date=trade_date
    )
    
    print(f"获取到 {len(weights_df)} 只成分股")
    
    # 3. 排序并添加排名
    weights_df = weights_df.sort_values('weight', ascending=False).reset_index(drop=True)
    weights_df['排名'] = range(1, len(weights_df) + 1)
    
    # 4. 获取股票名称和状态
    print("正在获取股票名称和状态...")
    stock_codes = weights_df['con_code'].tolist()
    
    # 分批获取名称和状态（避免一次请求太多）
    batch_size = 80
    all_info = []
    
    for i in range(0, len(stock_codes), batch_size):
        batch = stock_codes[i:i+batch_size]
        batch_str = ','.join(batch)
        
        # 获取代码、名称和状态
        info_df = pro.stock_basic(
            ts_code=batch_str,
            fields='ts_code,name,list_status'  # 只改了这里，添加了list_status
        )
        all_info.append(info_df)
    
    # 合并数据
    if all_info:
        info_df = pd.concat(all_info, ignore_index=True)
        
        # 合并到权重数据
        result_df = pd.merge(
            weights_df,
            info_df,
            left_on='con_code',
            right_on='ts_code',
            how='left'
        )
    else:
        result_df = weights_df.copy()
        result_df['name'] = ''
        result_df['list_status'] = ''
    
    # 5. 选择需要的列并重命名
    final_df = result_df[['排名', 'con_code', 'name', 'weight', 'list_status']].copy()  # 添加了list_status
    final_df = final_df.rename(columns={
        'con_code': '股票代码',
        'name': '股票名称',
        'weight': '权重(%)',
        'list_status': '上市状态'  # 添加了重命名
    })
    
    # 格式化权重（保留4位小数）
    final_df['权重(%)'] = final_df['权重(%)'].round(4)
    
    # 6. 保存为CSV
    final_df.to_csv('沪深300_成分股_20231229.csv', index=False, encoding='utf-8-sig')
    
    print("\n" + "=" * 50)
    print("数据获取完成！")
    print("=" * 50)
    
    # 显示前10名
    print("\n前10大权重股:")
    print(final_df.head(10).to_string(index=False))
    
    # 显示文件信息
    print(f"\n保存的文件: 沪深300_成分股_20231229.csv")
    print(f"数据行数: {len(final_df)} 行")
    print(f"数据列数: {len(final_df.columns)} 列")
    
    return final_df

# 运行程序
if __name__ == "__main__":
    df = main()






# 读取刚才保存的文件
df = pd.read_csv('沪深300_成分股_20231229.csv', encoding='utf-8-sig')

print(f"原始数据: {len(df)} 行")

# 1. 剔除异常状态（只保留L状态的）
# 上市状态为L才是正常上市
df_clean = df[df['上市状态'] == 'L'].copy()

print(f"剔除异常状态后: {len(df_clean)} 行")
print(f"剔除数量: {len(df) - len(df_clean)} 行")

# 显示被剔除的股票
abnormal_stocks = df[df['上市状态'] != 'L']
if len(abnormal_stocks) > 0:
    print("\n被剔除的异常状态股票:")
    print(abnormal_stocks[['股票代码', '股票名称', '上市状态']].to_string(index=False))

# 2. 删除数据缺失的（检查关键列）
# 关键列：排名、股票代码、股票名称、权重(%)、上市状态
key_columns = ['排名', '股票代码', '股票名称', '权重(%)', '上市状态']

# 检查每列的缺失情况
print("\n数据缺失检查:")
for col in key_columns:
    missing_count = df_clean[col].isnull().sum()
    if missing_count > 0:
        print(f"  {col}: 缺失 {missing_count} 行")

# 删除任何关键列有缺失的行
initial_count = len(df_clean)
df_clean = df_clean.dropna(subset=key_columns)

print(f"\n删除数据缺失后: {len(df_clean)} 行")
print(f"删除数量: {initial_count - len(df_clean)} 行")

# 重新排序排名（因为可能删除了行）
df_clean = df_clean.sort_values('权重(%)', ascending=False).reset_index(drop=True)
df_clean['排名'] = range(1, len(df_clean) + 1)

# 3. 保存清洗后的数据
output_file = '沪深300_成分股_清洗后_20231229.csv'
df_clean.to_csv(output_file, index=False, encoding='utf-8-sig')

print("\n" + "=" * 50)
print("清洗完成！")
print("=" * 50)
print(f"最终样本量: {len(df_clean)} 只股票")
print(f"保存到: {output_file}")

# 显示前10名
print("\n前10大权重股:")
print(df_clean[['排名', '股票代码', '股票名称', '权重(%)']].head(10).to_string(index=False))

# 显示状态分布（应该全是L）
print(f"\n最终上市状态分布:")
print(df_clean['上市状态'].value_counts())






# 读取原始CSV文件
file_path = '沪深300_成分股_清洗后_20231229.csv'

try:
    # 尝试不同的编码方式读取文件
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
    except:
        df = pd.read_csv(file_path, encoding='gbk')
    
    print(f"原始数据形状: {df.shape}")
    print(f"原始数据预览:")
    print(df.head())
    
    # 提取前34个股票
    top_34 = df.head(34).copy()
    
    # 要排除的股票列表
    exclude_stocks = ['300750.SZ', '600276.SH', '601328.SH', '601816.SH']
    exclude_names = ['宁德时代', '恒瑞医药', '交通银行', '京沪高铁']
    
    print(f"\n要排除的股票: {list(zip(exclude_stocks, exclude_names))}")
    
    # 筛选出不包含排除股票的数据
    final_30 = top_34[~top_34['股票代码'].isin(exclude_stocks)].copy()
    
    print(f"\n筛选后的股票数量: {len(final_30)}")
    
    # 重置排名列
    final_30['排名'] = range(1, len(final_30) + 1)
    
    
    # 保存到新的CSV文件
    output_file = '最终版_30个股票.csv'
    final_30.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\n 数据已成功保存到 '{output_file}'")
    print(f" 最终数据形状: {final_30.shape}")
    
   
    # 按交易所统计
    sh_count = final_30['股票代码'].str.endswith('.SH').sum()
    sz_count = final_30['股票代码'].str.endswith('.SZ').sum()
    print(f" 交易所分布: 上交所{sh_count}只, 深交所{sz_count}只")
    
except FileNotFoundError:
    print(f" 错误: 找不到文件 '{file_path}'")
    print("请确保文件在当前目录下，或者提供完整的文件路径")
except Exception as e:
    print(f" 读取文件时发生错误: {e}")
print(f"总权重占比: {final_30['权重(%)'].sum():.3f}%")




import warnings
import os
warnings.filterwarnings('ignore')


def get_stock_data(ts_code, start_date, end_date):
    """
    获取指定股票在指定时间段的所有参数数据
    
    参数:
    ts_code: 股票代码，如 '000001.SZ'
    start_date: 开始日期，格式 'YYYYMMDD'
    end_date: 结束日期，格式 'YYYYMMDD'
    
    返回:
    DataFrame: 包含所有参数的合并数据
    """
    try:
        print(f"正在获取 {ts_code} 从 {start_date} 到 {end_date} 的数据...")
        
        # 1. 获取个股日行情数据 (pro.daily)
        daily_data = pro.daily(
            ts_code=ts_code,
            start_date=start_date,
            end_date=end_date
        )
        
        if daily_data.empty:
            print(f"警告: {ts_code} 在指定时间段没有日行情数据")
            return pd.DataFrame()
        
        # 2. 获取每日基本面数据 (pro.daily_basic)
        basic_data = pro.daily_basic(
            ts_code=ts_code,
            start_date=start_date,
            end_date=end_date,
            fields='ts_code,trade_date,turnover_rate_f,total_mv,pe,pb'
        )
        
        if basic_data.empty:
            print(f"警告: {ts_code} 在指定时间段没有基本面数据")
            return pd.DataFrame()
        
        # 3. 获取沪深300指数数据 (pro.index_daily)
        hs300_data = pro.index_daily(
            ts_code='000300.SH',
            start_date=start_date,
            end_date=end_date,
            fields='trade_date,pct_chg'
        )
        
        # 重命名列以区分
        daily_data = daily_data.rename(columns={'pct_chg': 'stock_return', 'vol': 'volume', 'amount': 'amount'})
        basic_data = basic_data.rename(columns={
            'turnover_rate_f': 'turnover_rate',
            'total_mv': 'market_cap',
            'pe': 'pe_ratio',
            'pb': 'pb_ratio'
        })
        hs300_data = hs300_data.rename(columns={'pct_chg': 'market_return'})
        
        # 4. 合并所有数据
        # 首先合并个股日行情和基本面数据
        merged_data = pd.merge(
            daily_data[['ts_code', 'trade_date', 'stock_return', 'volume', 'amount']],
            basic_data[['ts_code', 'trade_date', 'turnover_rate', 'market_cap', 'pe_ratio', 'pb_ratio']],
            on=['ts_code', 'trade_date'],
            how='left'
        )
        
        # 然后合并市场数据
        merged_data = pd.merge(
            merged_data,
            hs300_data[['trade_date', 'market_return']],
            on='trade_date',
            how='left'
        )
        
        # 5. 按日期排序
        merged_data['trade_date'] = pd.to_datetime(merged_data['trade_date'])
        merged_data = merged_data.sort_values('trade_date').reset_index(drop=True)
        
        # 6. 重新排列列顺序
        column_order = ['ts_code', 'trade_date', 'stock_return', 'market_return', 
                       'turnover_rate', 'market_cap', 'pe_ratio', 'pb_ratio', 
                       'volume', 'amount']
        merged_data = merged_data[column_order]
        
        print(f"成功获取 {len(merged_data)} 条记录")
        return merged_data
        
    except Exception as e:
        print(f"获取数据时发生错误: {e}")
        return pd.DataFrame()






# 定义两个时间段
periods = {
    'period_2022': ('20220225', '20220630'),
    'period_2023': ('20230225', '20230630')
}

# 创建保存数据的文件夹
output_dir = 'stock_data'
os.makedirs(output_dir, exist_ok=True)

# 存储所有数据
all_stocks_data = []

print(f"开始获取 {len(stock_codes)} 只股票的数据...")
print("="*50)

for code in stock_codes:
    print(f"\n正在获取股票: {code}")
    
    # 获取该股票在两个时间段的数据
    stock_all_data = []
    
    for period_name, (start_date, end_date) in periods.items():
        print(f"  时间段: {period_name} ({start_date} 到 {end_date})")
        data = get_stock_data(code, start_date, end_date)
        
        if not data.empty:
            # 添加时间段标记
            data['period'] = period_name
            stock_all_data.append(data)
            print(f"    获取到 {len(data)} 条记录")
        else:
            print(f"    无数据")
    
    # 如果该股票有数据，添加到总数据中
    if stock_all_data:
        combined_stock_data = pd.concat(stock_all_data, ignore_index=True)
        all_stocks_data.append(combined_stock_data)

# 合并所有股票的数据
if all_stocks_data:
    final_data = pd.concat(all_stocks_data, ignore_index=True)
    
    # 保存为单个CSV文件
    output_file = f'{output_dir}/all_stocks_data.csv'
    final_data.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\n{'='*50}")
    print("数据获取完成！")
    print(f"保存文件: {output_file}")
    print(f"总股票数: {final_data['ts_code'].nunique()}")
    print(f"总记录数: {len(final_data)}")
    print(f"数据时间段: {final_data['period'].unique()}")
    print(f"数据预览:")
    print(final_data.head())
else:
    print("\n未获取到任何数据")






def add_year_to_date_in_csv(file_path, year):
    """为CSV文件中的日期添加年份"""
    try:
        # 读取CSV文件
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        
        # 检查是否包含"发帖时间"列
        if '发帖时间' not in df.columns:
            print(f"警告: {file_path} 中没有'发帖时间'列，跳过处理")
            return
        
        # 遍历每一行的"发帖时间"列
        for i, date_str in enumerate(df['发帖时间']):
            # 如果日期没有年份，格式为 "MM-DD HH:MM"
            if isinstance(date_str, str) and re.match(r'^\d{2}-\d{2} \d{2}:\d{2}$', date_str):
                # 添加年份和横杠，转换为 "YYYY-MM-DD HH:MM"
                df.at[i, '发帖时间'] = f"{year}-{date_str}"
        
        # 保存回原文件
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        print(f" 已处理: {file_path}")
        
    except Exception as e:
        print(f" 处理 {file_path} 时出错: {e}")

def batch_process_csv_files(directory):
    """批量处理指定目录下的CSV文件"""
    print(f"正在处理目录: {directory}")
    print("-" * 50)
    
    processed_count = 0
    skipped_count = 0
    
    # 遍历目录下所有文件
    for filename in os.listdir(directory):
        if filename.endswith('.csv') and filename.startswith('2023'):
            # 提取文件名中的年份（假设文件名以"YYYYMMDD-"开头）
            match = re.match(r'^(\d{4})\d{4}-', filename)
            if match:
                year = match.group(1)  # 提取年份
                file_path = os.path.join(directory, filename)
                add_year_to_date_in_csv(file_path, year)
                processed_count += 1
            else:
                print(f"警告: {filename} 格式不符合要求，跳过处理")
                skipped_count += 1
    
    print("-" * 50)
    print(f"处理完成！")
    print(f"成功处理: {processed_count} 个文件")
    print(f"跳过处理: {skipped_count} 个文件")

# 使用示例：指定CSV文件所在目录
csv_directory = r"C:/Users/Lenovo/Desktop/financial_data_analysis/"  # 使用原始字符串或双反斜杠
batch_process_csv_files(csv_directory)





# 设置文件夹路径
folder_path = r"C:/Users/Lenovo/Desktop/financial_data_analysis/"

# 获取2022和2023开头的CSV文件
csv_files = []
for file in os.listdir(folder_path):
    if file.endswith('.csv') and (file.startswith('2022') or file.startswith('2023')):
        csv_files.append(os.path.join(folder_path, file))

print(f"找到 {len(csv_files)} 个2022/2023开头的CSV文件")

# 读取并合并所有文件
all_data = []

for file in csv_files:
    file_name = os.path.basename(file)
    
    # 从文件名提取股票代码（在括号内的6位数字）
    match = re.search(r'\((\d{6})\)', file_name)
    
    if match:
        stock_code = match.group(1)  # 只提取6位数字
        
        # 读取CSV文件
        df = pd.read_csv(file, encoding='utf-8-sig')
        
        # 添加股票代码列
        df['股票代码'] = stock_code
        
        all_data.append(df)
        print(f"已处理: {file_name} -> 股票代码: {stock_code}, 数据行数: {len(df)}")
    else:
        print(f"跳过: {file_name} (无法提取股票代码)")

# 合并所有数据
if all_data:
    merged_df = pd.concat(all_data, ignore_index=True)
    
    # 保存合并文件
    output_file = os.path.join(folder_path, "2022_2023_合并数据.csv")
    merged_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\n合并完成!")
    print(f"总数据行数: {len(merged_df)}")
    print(f"唯一股票数量: {merged_df['股票代码'].nunique()}")
    print(f"保存到: {output_file}")
    
    # 显示预览
    print(f"\n数据预览（前5行）:")
    print(merged_df.head())
else:
    print("没有处理任何文件")


from datetime import datetime

# 1. 设置路径
folder_path = r"C:/Users/Lenovo/Desktop/financial_data_analysis/"  # 修改为你的实际路径
merged_file = os.path.join(folder_path, "2022_2023_合并数据.csv")  # 合并后的评论数据
stock_data_file = os.path.join(folder_path, "all_stocks_data.csv")  # 股票交易日数据文件
output_file = os.path.join(folder_path, "交易日的评论数据.csv")  # 输出文件

# 2. 读取合并的评论数据
print("读取评论数据...")
try:
    merged_df = pd.read_csv(merged_file, encoding='utf-8-sig')
    print(f"评论数据: {len(merged_df)} 行")
except:
    print(f"找不到文件: {merged_file}")
    exit()

# 3. 读取股票交易日数据
print("\n读取股票交易日数据...")
try:
    stock_df = pd.read_csv(stock_data_file, encoding='utf-8-sig')
    print(f"股票数据: {len(stock_df)} 行")
    
    # 使用 trade_data 列
    if 'trade_date' in stock_df.columns:
        # 提取交易日期列表
        trade_dates = stock_df['trade_date'].astype(str).str[:10].unique()  # 取前10位（YYYY-MM-DD格式）
        print(f"找到 {len(trade_dates)} 个交易日")
        print(f"交易日示例: {trade_dates[:5]}")
    else:
        print(f"股票数据中没有 'trade_data' 列")
        print(f"可用列名: {list(stock_df.columns)}")
        exit()
        
except Exception as e:
    print(f"读取股票数据出错: {e}")
    exit()

# 4. 从评论数据中提取日期
print("\n处理评论数据日期...")
# 找到评论时间列（假设是'发帖时间'）
time_col = '发帖时间'  # 根据实际情况修改

if time_col not in merged_df.columns:
    print(f"评论数据中没有 '{time_col}' 列")
    print(f"可用列名: {list(merged_df.columns)}")
    # 尝试其他常见列名
    for col in ['时间', 'date', 'Date', 'timestamp']:
        if col in merged_df.columns:
            time_col = col
            print(f"使用 '{time_col}' 作为时间列")
            break
    else:
        print("未找到时间列，请手动指定")
        exit()

print(f"使用 '{time_col}' 作为评论时间列")

# 从评论时间中提取日期（YYYY-MM-DD格式）
def extract_date(time_str):
    if pd.isna(time_str):
        return None
    
    time_str = str(time_str).strip()
    
    # 去除可能的引号
    time_str = time_str.replace('"', '').replace("'", "")
    
    # 如果包含空格，取空格前的部分
    if ' ' in time_str:
        date_part = time_str.split(' ')[0]
    else:
        date_part = time_str
    
    # 处理不同格式的日期
    # 格式1: "2022-05-17" 或 "2022/05/17"
    if len(date_part) == 10:
        # 统一转为 YYYY-MM-DD 格式
        if '/' in date_part:
            date_part = date_part.replace('/', '-')
        return date_part
    
    # 格式2: "05-17" 或 "05/17" (只有月日)
    elif len(date_part) == 5 and (date_part.count('-') == 1 or date_part.count('/') == 1):
        # 统一转为 MM-DD 格式
        if '/' in date_part:
            date_part = date_part.replace('/', '-')
        
        # 尝试2022和2023年
        for year in ['2022', '2023']:
            full_date = f"{year}-{date_part}"
            if full_date in trade_dates:
                return full_date
        return None
    
    # 格式3: "20220517" (数字格式)
    elif len(date_part) == 8 and date_part.isdigit():
        try:
            dt = datetime.strptime(date_part, '%Y%m%d')
            return dt.strftime('%Y-%m-%d')
        except:
            return None
    
    # 其他格式，尝试解析
    else:
        for fmt in ['%Y-%m-%d', '%Y/%m/%d', '%Y%m%d', '%m-%d', '%m/%d']:
            try:
                dt = datetime.strptime(date_part, fmt)
                if fmt in ['%m-%d', '%m/%d']:
                    # 只有月日，需要补全年份
                    for year in ['2022', '2023']:
                        full_date = f"{year}-{dt.month:02d}-{dt.day:02d}"
                        if full_date in trade_dates:
                            return full_date
                    return None
                else:
                    return dt.strftime('%Y-%m-%d')
            except:
                continue
        return None

# 提取评论日期
merged_df['评论日期'] = merged_df[time_col].apply(extract_date)

# 统计有多少行提取到了日期
valid_dates = merged_df['评论日期'].notna().sum()
print(f"成功提取日期: {valid_dates}/{len(merged_df)} 行")

# 5. 过滤非交易日的评论
print(f"\n过滤非交易日的评论...")
print(f"过滤前: {len(merged_df)} 行")

# 只保留交易日的评论
filtered_df = merged_df[merged_df['评论日期'].isin(trade_dates)].copy()

print(f"过滤后: {len(filtered_df)} 行")
print(f"删除了 {len(merged_df) - len(filtered_df)} 行非交易日评论")

# 6. 按日期排序
if not filtered_df.empty and '评论日期' in filtered_df.columns:
    filtered_df = filtered_df.sort_values('评论日期')

# 7. 保存结果
print(f"\n保存结果到: {output_file}")
filtered_df.to_csv(output_file, index=False, encoding='utf-8-sig')

# 8. 显示统计信息
print("\n=== 统计信息 ===")
print(f"总评论数: {len(merged_df)}")
print(f"交易日评论数: {len(filtered_df)} ({len(filtered_df)/len(merged_df)*100:.1f}%)")
print(f"非交易日评论数: {len(merged_df) - len(filtered_df)}")

# 按日期统计
if len(filtered_df) > 0 and '评论日期' in filtered_df.columns:
    daily_counts = filtered_df['评论日期'].value_counts().sort_index()
    print(f"\n每日评论数量统计:")
    for date, count in daily_counts.head(10).items():
        print(f"  {date}: {count} 条评论")
    
    # 总统计
    print(f"\n评论日期范围: {filtered_df['评论日期'].min()} 到 {filtered_df['评论日期'].max()}")
    print(f"有评论的交易日数: {len(daily_counts)}")

print(f"\n处理完成！结果已保存到: {output_file}")

# 9. 显示前几行数据预览
print("\n处理后的数据前5行预览:")
print(filtered_df.head())




# 读取CSV文件
file_path = "交易日的评论数据.csv"  # 修改为你的文件路径
df = pd.read_csv(file_path, encoding='utf-8-sig')

# 1. 删除“发帖时间”列（如果存在）
if '发帖时间' in df.columns:
    df = df.drop(columns=['发帖时间'])
    print("已删除'发帖时间'列")
else:
    print("文件中没有'发帖时间'列")

# 2. 把“股票代码”列挪到最前面（如果存在）
if '股票代码' in df.columns:
    # 获取所有列名
    cols = list(df.columns)
    # 把“股票代码”列移到最前面
    cols = ['股票代码'] + [col for col in cols if col != '股票代码']
    # 重新排列列顺序
    df = df[cols]
    print("已将'股票代码'列移动到最前面")
else:
    print("文件中没有'股票代码'列")

# 保存回原文件（覆盖原文件）
df.to_csv(file_path, index=False, encoding='utf-8-sig')

print(f"文件已更新！")
print(f"当前列顺序: {list(df.columns)}")
print(f"数据形状: {df.shape}")




# 读取CSV文件
df = pd.read_csv('mda_results.csv', encoding='utf-8-sig')

# 提取mda_text列
mda_texts = df['管理层讨论与分析']

# 显示前3个
for i, text in enumerate(mda_texts.head(3)):
    print(f"=== 第{i+1}个文件 ===")
    print(text[:500])  # 只显示前500字符
    print(f"字符数: {len(text)}")
    print("="*50 + "\n")



import pandas as pd
import jieba

# 加载词表函数
def load_wordlist(file_path):
    return set(line.strip() for line in open(file_path, 'r', encoding='utf-8') if line.strip())

# 主处理函数
def analyze_comments(comments_file, output_file):
    # 加载词表
    stopwords = load_wordlist('hit_stopwords.txt') | load_wordlist('baidu_stopwords.txt')
    positive_words = load_wordlist('非正式积极.txt')
    negative_words = load_wordlist('非正式消极.txt')
    
    # 读取评论数据
    df = pd.read_csv(comments_file)
    
    # 检查必要的列
    required_cols = ['股票代码', '评论日期', '标题']
    for col in required_cols:
        if col not in df.columns:
            print(f"错误: 数据文件缺少'{col}'列")
            print(f"现有列: {list(df.columns)}")
            return pd.DataFrame()
    
    # 按股票代码和日期双重分组处理
    results = []
    
    # 先按股票代码分组，再按日期分组
    for stock_code, stock_group in df.groupby('股票代码'):
        for date, date_group in stock_group.groupby('评论日期'):
            total, positive, negative = 0, 0, 0
            
            for comment in date_group['标题']:
                if pd.isna(comment):
                    continue
                    
                words = [w for w in jieba.lcut(str(comment)) if w not in stopwords and len(w) > 1]
                total += len(words)
                positive += sum(1 for w in words if w in positive_words)
                negative += sum(1 for w in words if w in negative_words)
            
            results.append([stock_code, date, total, positive, negative])
    
    # 保存结果
    result_df = pd.DataFrame(results, columns=['股票代码', 'date', 'total_words', 'positive_words', 'negative_words'])
    
    # 按股票代码和日期排序
    result_df['date'] = pd.to_datetime(result_df['date'])
    result_df = result_df.sort_values(['股票代码', 'date']).reset_index(drop=True)
    result_df['date'] = result_df['date'].dt.strftime('%Y-%m-%d')
    
    result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"分析完成！")
    print(f"处理了 {result_df['股票代码'].nunique()} 只股票")
    print(f"总记录数: {len(result_df)}")
    print(f"日期范围: {result_df['date'].min()} 到 {result_df['date'].max()}")
    
    return result_df

# 使用
results = analyze_comments('交易日的评论数据.csv', '评论情绪分析结果.csv')
print("\n结果预览:")
print(results.head())


# 读取已有的评论情绪分析结果文件
df = pd.read_csv('评论情绪分析结果.csv', encoding='utf-8-sig')

# 计算情绪指标: (积极词数 - 消极词数) / 全部词数，保留三位小数
df['sentiment_score'] = ((df['positive_words'] - df['negative_words']) / df['total_words'].replace(0, 1)).round(3)

# 保存回原文件
df.to_csv('评论情绪分析结果.csv', index=False, encoding='utf-8-sig')

print("前5行数据：")
print(df.head())
print(f"\n数据形状: {df.shape}")
print(f"当前列: {list(df.columns)}")





# 读取评论情绪分析结果文件
df = pd.read_csv('评论情绪分析结果.csv', encoding='utf-8-sig')

print(f"原始数据形状: {df.shape}")
print(f"股票代码列示例: {df['股票代码'].head().tolist()}")

# 将股票代码转换为六位数格式
df['股票代码'] = df['股票代码'].astype(str).str.zfill(6)

# 保存回原文件
df.to_csv('评论情绪分析结果.csv', index=False, encoding='utf-8-sig')

print(f"\n转换后:")
print(f"股票代码列示例: {df['股票代码'].head().tolist()}")
print(f"唯一股票代码数量: {df['股票代码'].nunique()}")
print("\n数据已保存!")



# 读取评论情绪分析结果文件
df = pd.read_csv('评论情绪分析结果.csv', encoding='utf-8-sig')

print(f"原始数据形状: {df.shape}")
print(f"原始数据列: {list(df.columns)}")

# 删除倒数第二、三、四列
if len(df.columns) >= 4:
    # 计算要保留的列索引：去掉倒数第2,3,4列
    keep_columns = df.columns[:-4].tolist()  # 保留除了最后4列的所有列
    keep_columns.append(df.columns[-1])      # 加上最后一列
    
    df_new = df[keep_columns]
    
    # 保存为新文件
    df_new.to_csv('评论情绪指标.csv', index=False, encoding='utf-8-sig')
    
    print(f"\n新文件数据形状: {df_new.shape}")
    print(f"新文件列: {list(df_new.columns)}")
    print("\n新文件前5行数据:")
    print(df_new.head())
else:
    print(f"数据只有 {len(df.columns)} 列，无法删除倒数二三四列")




# 读取评论情绪分析结果文件
df = pd.read_csv('评论情绪指标.csv', encoding='utf-8-sig')

print(f"原始数据形状: {df.shape}")
print(f"股票代码列示例: {df['股票代码'].head().tolist()}")

# 将股票代码转换为六位数格式
df['股票代码'] = df['股票代码'].astype(str).str.zfill(6)

# 保存回原文件
df.to_csv('评论情绪指标.csv', index=False, encoding='utf-8-sig')

print(f"\n转换后:")
print(f"股票代码列示例: {df['股票代码'].head().tolist()}")
print(f"唯一股票代码数量: {df['股票代码'].nunique()}")
print("\n数据已保存!")




import os

# 1. 读取数据
df = pd.read_csv('mda_all_companies.csv', encoding='utf-8-sig')
print(f"读取到 {len(df)} 条记录")

# 2. 加载停用词表
def load_stopwords(stopword_files):
    """加载停用词表"""
    stopwords = set()
    for file in stopword_files:
        if os.path.exists(file):
            with open(file, 'r', encoding='utf-8') as f:
                for line in f:
                    word = line.strip()
                    if word:
                        stopwords.add(word)
            print(f"从 {file} 加载了 {len([w for w in stopwords if w])} 个停用词")
        else:
            print(f"警告：停用词文件 {file} 不存在")
    return stopwords

stopword_files = ['hit_stopwords.txt', 'baidu_stopwords.txt']
stopwords = load_stopwords(stopword_files)

# 3. 加载情感词表
def load_sentiment_words(positive_file, negative_file):
    """加载积极和消极词表"""
    positive_words = set()
    negative_words = set()
    
    # 加载积极词
    if os.path.exists(positive_file):
        with open(positive_file, 'r', encoding='utf-8') as f:
            for line in f:
                word = line.strip()
                if word:
                    positive_words.add(word)
        print(f"从 {positive_file} 加载了 {len(positive_words)} 个积极词")
    else:
        print(f"警告：积极词表 {positive_file} 不存在")
    
    # 加载消极词
    if os.path.exists(negative_file):
        with open(negative_file, 'r', encoding='utf-8') as f:
            for line in f:
                word = line.strip()
                if word:
                    negative_words.add(word)
        print(f"从 {negative_file} 加载了 {len(negative_words)} 个消极词")
    else:
        print(f"警告：消极词表 {negative_file} 不存在")
    
    return positive_words, negative_words

positive_file = '正式积极.txt'
negative_file = '正式消极.txt'
positive_words, negative_words = load_sentiment_words(positive_file, negative_file)

# 4. 分词和统计函数
def analyze_text(text, stopwords, positive_words, negative_words):
    """分析文本，返回词数统计"""
    if pd.isna(text) or not isinstance(text, str):
        return 0, 0, 0
    
    # 分词
    words = jieba.lcut(text)
    
    # 过滤停用词和非中文字符
    filtered_words = []
    for word in words:
        word = word.strip()
        if word and word not in stopwords:
            # 只保留中文字符（可选）
            if any('\u4e00' <= char <= '\u9fff' for char in word):
                filtered_words.append(word)
    
    # 统计
    total_words = len(filtered_words)
    
    # 统计积极词
    positive_count = 0
    for word in filtered_words:
        if word in positive_words:
            positive_count += 1
    
    # 统计消极词
    negative_count = 0
    for word in filtered_words:
        if word in negative_words:
            negative_count += 1
    
    return total_words, positive_count, negative_count

# 5. 批量处理所有文本
print(f"\n开始分析文本...")
print("-" * 50)

results = []
for idx, row in df.iterrows():
    company = row['公司名称']
    year = row['年份']
    text = row['MD&A文本']
    
    print(f"处理 [{idx+1}/{len(df)}]: {company} {year}")
    
    # 分析文本
    word_count, positive_count, negative_count = analyze_text(
        text, stopwords, positive_words, negative_words
    )
    
    # 计算语调指标
    net_tone = positive_count - negative_count  # 净积极词数
    tone_ratio = (positive_count - negative_count) / (word_count + 1) if word_count > 0 else 0  # 语调比率
    
    results.append({
        '公司名称': company,
        '年份': year,
        '总词数': word_count,
        '积极词数': positive_count,
        '消极词数': negative_count, 
    })
    
    print(f"  词数: {word_count}, 积极: {positive_count}, 消极: {negative_count}")

# 6. 保存结果
output_df = pd.DataFrame(results)
output_file = '年报语调指标.csv'
output_df.to_csv(output_file, index=False, encoding='utf-8-sig')

print(f"\n分析完成！")
print(f"   保存到: {output_file}")
print(f"   共分析 {len(results)} 条记录")

# 7. 显示统计摘要
print(f"\n统计摘要:")
summary = output_df[['总词数', '积极词数', '消极词数']].describe()
print(summary)

# 8. 显示前10条结果
print(f"\n前10条结果:")
print(output_df.head(10).to_string(index=False))





# 1. 读取现有的语调指标文件
input_file = '年报语调指标.csv'
df = pd.read_csv(input_file, encoding='utf-8-sig')

print(f"读取文件: {input_file}")
print(f"原数据行数: {len(df)}")
print(f"原数据列: {list(df.columns)}")

# 2. 计算情绪指标 (积极词数 - 消极词数) / 总词数
def calculate_sentiment_index(row):
    total_words = row['总词数']
    if total_words > 0:
        return (row['积极词数'] - row['消极词数']) / total_words
    else:
        return 0

# 添加新列
df['情绪指标'] = df.apply(calculate_sentiment_index, axis=1)
df['情绪指标'] = df['情绪指标'].round(4)  # 保留6位小数

# 3. 保存回原文件
df.to_csv(input_file, index=False, encoding='utf-8-sig')

print(f"\n 已添加'情绪指标'列到 {input_file}")
print(f"新数据列: {list(df.columns)}")

# 4. 显示统计信息
print(f"\n 情绪指标统计:")
print(f"平均值: {df['情绪指标'].mean():.6f}")
print(f"最小值: {df['情绪指标'].min():.6f}")
print(f"最大值: {df['情绪指标'].max():.6f}")

# 5. 显示前10行数据
print(f"\n 前10行数据:")
print(df[['公司名称', '年份', '总词数', '积极词数', '消极词数', '情绪指标']].head(10).to_string(index=False))









# 1. 读取两个文件
tone_df = pd.read_csv('年报语调指标.csv', encoding='utf-8-sig')
stock_df = pd.read_csv('最终版_30个股票.csv', encoding='utf-8-sig')

print(f"原文件行数: {len(tone_df)}")
print(f"股票文件行数: {len(stock_df)}")

# 2. 查看股票文件的列结构
print("\n股票文件列名:", list(stock_df.columns))

# 假设股票文件有'股票代码'和'股票名称'两列
if '股票代码' not in stock_df.columns or '股票名称' not in stock_df.columns:
    print("错误：股票文件缺少'股票代码'或'股票名称'列")
    print("实际列名:", list(stock_df.columns))
    exit()

# 3. 在最前面插入股票代码列
tone_df.insert(0, '股票代码', '')

# 4. 根据公司名称匹配股票代码
for idx, row in tone_df.iterrows():
    company_name = str(row['公司名称']).strip()
    
    # 在股票文件中查找匹配
    match = stock_df[stock_df['股票名称'] == company_name]
    
    if not match.empty:
        # 找到完全匹配
        stock_code = match.iloc[0]['股票代码']
        tone_df.at[idx, '股票代码'] = stock_code
    else:
        # 尝试部分匹配
        for _, stock_row in stock_df.iterrows():
            stock_name = str(stock_row['股票名称']).strip()
            if stock_name in company_name or company_name in stock_name:
                tone_df.at[idx, '股票代码'] = stock_row['股票代码']
                # 将公司名称改为股票名称
                tone_df.at[idx, '公司名称'] = stock_name
                break

# 5. 直接覆盖原文件
tone_df.to_csv('年报语调指标.csv', index=False, encoding='utf-8-sig')

print(f"\n 修改完成！已直接更新'年报语调指标.csv'")
print(f"新列顺序: {list(tone_df.columns)}")

# 6. 显示修改后的前几行
print("\n 修改后的数据预览:")
print(tone_df.head().to_string(index=False))



# 1. 读取文件
tone_df = pd.read_csv('年报语调指标.csv', encoding='utf-8-sig')

print(f"原文件行数: {len(tone_df)}")
print("前20行数据:")
print(tone_df.head(20).to_string(index=False))

# 2. 确保有股票代码列
if '股票代码' not in tone_df.columns:
    tone_df.insert(0, '股票代码', '')

# 3. 直接修改指定行（注意：索引从0开始，行号从1开始）
# 第13行 -> 索引12
# 第14行 -> 索引13
# 第15行 -> 索引14
# 第16行 -> 索引15

# 修改第13、14行
tone_df.at[12, '股票代码'] = '000858.SZ'  # 第13行
tone_df.at[13, '股票代码'] = '000858.SZ'  # 第14行

# 修改第15、16行
tone_df.at[14, '股票代码'] = '000725.SZ'  # 第15行
tone_df.at[15, '股票代码'] = '000725.SZ'  # 第16行

# 4. 覆盖保存
tone_df.to_csv('年报语调指标.csv', index=False, encoding='utf-8-sig')

print(f"\n修改完成！")
print("修改后的第10-18行:")
print(tone_df.iloc[9:18].to_string(index=False))




# 1. 读取文件
df = pd.read_csv('年报语调指标.csv', encoding='utf-8-sig')

print(f"原文件行数: {len(df)}")
print(f"原文件列名: {list(df.columns)}")

# 2. 删除指定的列
columns_to_drop = ['总词数', '积极词数', '消极词数']
for col in columns_to_drop:
    if col in df.columns:
        df = df.drop(columns=[col])
        print(f"已删除列: {col}")
    else:
        print(f"列不存在: {col}")

# 3. 将'公司名称'列名改为'股票名称'
if '公司名称' in df.columns:
    df = df.rename(columns={'公司名称': '股票名称'})
    print("已将'公司名称'列名改为'股票名称'")
else:
    print("未找到'公司名称'列")

# 4. 保存为新文件
output_file = '年报语调终版.csv'
df.to_csv(output_file, index=False, encoding='utf-8-sig')

print(f"\n 处理完成！保存到: {output_file}")
print(f"新文件列名: {list(df.columns)}")
print(f"新文件行数: {len(df)}")

# 5. 显示前10行数据
print("\n 前10行数据预览:")
print(df.head(10).to_string(index=False))





import re

# 1. 读取文件夹中的股吧文件名
folder_path = "C:/Users/Lenovo/Desktop/financial_data_analysis/股吧评论/"  
files = [f for f in os.listdir(folder_path) if f.endswith('.csv') and '股吧' in f]

print(f"找到 {len(files)} 个股吧文件")

# 2. 创建股票代码到日期的映射
date_mapping = {}
for filename in files:
    # 提取日期：20220315 -> 2022-03-15
    date_match = re.search(r'(\d{4})(\d{2})(\d{2})', filename)
    if date_match:
        year, month, day = date_match.groups()
        formatted_date = f"{year}-{month}-{day}"
        
        # 提取股票代码：括号内的6位数字
        code_match = re.search(r'\((\d{6})\)', filename)
        if code_match:
            stock_code = code_match.group(1)
            date_mapping[stock_code] = formatted_date

print(f"\n创建了 {len(date_mapping)} 个股票代码到日期的映射")
for code, date in list(date_mapping.items())[:5]:  # 显示前5个
    print(f"  股票代码 {code} -> 发布日期 {date}")

# 3. 读取并修改原文件
df = pd.read_csv('年报语调终版.csv', encoding='utf-8-sig')
print(f"\n原文件行数: {len(df)}")

# 4. 添加发布日期列
df['发布日期'] = ''

# 5. 填充发布日期
match_count = 0
for idx, row in df.iterrows():
    # 获取股票代码（去掉.SZ等后缀）
    stock_code_full = str(row['股票代码']).strip()
    
    # 提取纯数字股票代码
    if '.' in stock_code_full:
        stock_code_num = stock_code_full.split('.')[0]
    else:
        stock_code_num = stock_code_full
    
    # 在映射中查找
    if stock_code_num in date_mapping:
        df.at[idx, '发布日期'] = date_mapping[stock_code_num]
        match_count += 1
    else:
        # 如果没有找到，尝试其他格式
        for code, date in date_mapping.items():
            if code in stock_code_num or stock_code_num in code:
                df.at[idx, '发布日期'] = date
                match_count += 1
                break

# 6. 直接覆盖原文件
df.to_csv('年报语调终版.csv', index=False, encoding='utf-8-sig')

print(f"\n 修改完成！已直接更新'年报语调终版.csv'")
print(f"匹配成功: {match_count}/{len(df)} 条记录")




# 1. 读取文件夹中的股吧文件
folder_path = "C:/Users/Lenovo/Desktop/financial_data_analysis/股吧评论/"  
files = [f for f in os.listdir(folder_path) if f.endswith('.csv') and '股吧' in f]

print(f"找到 {len(files)} 个股吧文件")

# 2. 创建映射：股票代码 -> {年份: 发布日期}
stock_date_mapping = {}
for filename in files:
    # 提取日期
    date_match = re.search(r'(\d{4})(\d{2})(\d{2})', filename)
    if date_match:
        year, month, day = date_match.groups()
        formatted_date = f"{year}-{month}-{day}"
        file_year = year  # 文件中的年份，如2022
        
        # 提取股票代码
        code_match = re.search(r'\((\d{6})\)', filename)
        if code_match:
            stock_code = code_match.group(1)
            
            # 添加到映射
            if stock_code not in stock_date_mapping:
                stock_date_mapping[stock_code] = {}
            
            stock_date_mapping[stock_code][file_year] = formatted_date

print(f"\n创建了 {len(stock_date_mapping)} 只股票的日期映射")

# 3. 读取并修改终版文件
df = pd.read_csv('年报语调终版.csv', encoding='utf-8-sig')
print(f"\n终版文件行数: {len(df)}")

# 4. 添加发布日期列
df['发布日期'] = ''

# 5. 根据年份匹配发布日期
match_count = 0
for idx, row in df.iterrows():
    # 获取股票代码（去掉后缀）
    stock_code_full = str(row['股票代码']).strip()
    stock_code_num = stock_code_full.split('.')[0] if '.' in stock_code_full else stock_code_full
    
    # 获取年份
    report_year = str(row['年份']).strip()
    

    if report_year.isdigit():
        file_year_to_match = str(int(report_year) + 1)
        
        # 查找该股票对应的发布日期
        if stock_code_num in stock_date_mapping:
            stock_dates = stock_date_mapping[stock_code_num]
            
            # 找对应年份的日期
            if file_year_to_match in stock_dates:
                df.at[idx, '发布日期'] = stock_dates[file_year_to_match]
                match_count += 1
            else:
                print(f"  ⚠ 未找到: 股票{stock_code_num}的{file_year_to_match}年日期")

# 6. 直接覆盖原文件
df.to_csv('年报语调终版.csv', index=False, encoding='utf-8-sig')

print(f"\n 修改完成！已直接更新'年报语调终版.csv'")
print(f"匹配成功: {match_count}/{len(df)} 条记录")

# 7. 显示结果
print("\n 修改后的数据预览:")
print(df[['股票代码', '年份', '发布日期']].head(15).to_string(index=False))



# 先读取
comment_df = pd.read_csv('评论情绪指标.csv', encoding='utf-8-sig')

print("转换前:")
print(comment_df['股票代码'].head())
print(f"数据类型: {comment_df['股票代码'].dtype}")

# 转换股票代码列：确保6位数字，前面补0
def format_stock_code(code):
    if pd.isna(code):
        return ''
    # 转换为字符串
    code_str = str(int(code)) if isinstance(code, (int, float)) else str(code)
    # 补齐6位
    return code_str.zfill(6)

comment_df['股票代码'] = comment_df['股票代码'].apply(format_stock_code)

print("\n转换后:")
print(comment_df['股票代码'].head())
print(f"数据类型: {comment_df['股票代码'].dtype}")






# 1. 读取文件
tone_df = pd.read_csv('年报语调终版.csv', encoding='utf-8-sig')
comment_df = pd.read_csv('评论情绪指标.csv', 
                         dtype={'股票代码': str},  # 指定股票代码为字符串
                         encoding='utf-8-sig')

print(f"年报语调终版: {len(tone_df)} 行（应该有60个值）")
print(f"评论情绪指标: {len(comment_df)} 行")

# 2. 统一股票代码格式
# 年报文件：提取6位数字代码
tone_df['股票代码_纯数字'] = tone_df['股票代码'].str.split('.').str[0]
tone_df['股票代码_纯数字'] = tone_df['股票代码_纯数字'].apply(
    lambda x: str(x).zfill(6) if pd.notna(x) and str(x).strip() != '' else ''
)

# 评论文件：确保是6位字符串（000333而不是333）
comment_df['股票代码'] = comment_df['股票代码'].apply(
    lambda x: str(x).zfill(6) if pd.notna(x) and str(x).strip() != '' else ''
)

print("\n=== 股票代码格式检查 ===")
print("评论文件股票代码示例（前10个）:")
print(comment_df['股票代码'].head(10).tolist())

print("\n年报文件股票代码_纯数字示例（前10个）:")
print(tone_df['股票代码_纯数字'].head(10).tolist())

# 3. 日期处理
tone_df['发布日期'] = pd.to_datetime(tone_df['发布日期']).dt.date
comment_df['date'] = pd.to_datetime(comment_df['date']).dt.date

# 4. 为每个年报找到对应的交易日和填充位置
tone_matches = []  # 存储匹配信息

for idx, row in tone_df.iterrows():
    stock_code_6digit = row['股票代码_纯数字']  # 6位代码，如"000333"
    stock_name = row['股票名称']
    stock_code_full = row['股票代码']  # 完整代码，如"000333.SZ"
    report_date = row['发布日期']
    annual_tone = row['情绪指标']
    
    print(f"\n处理: {stock_name}({stock_code_full}) [6位: {stock_code_6digit}]")
    
    # 获取该股票的所有交易日（用6位代码匹配）
    stock_comments = comment_df[comment_df['股票代码'] == stock_code_6digit]
    
    if stock_comments.empty:
        print(f"  ⚠ 股票{stock_code_6digit}在评论文件中没有数据")
        continue
    
    stock_dates = sorted(stock_comments['date'].unique())
    print(f"  找到{len(stock_dates)}个交易日，日期范围: {stock_dates[0]} 到 {stock_dates[-1]}")
    
    # 找到报告日或之后第一个交易日
    target_date = None
    for date in stock_dates:
        if date >= report_date:
            target_date = date
            break
    
    if target_date:
        # 找到评论文件中该日期的行索引
        target_rows = stock_comments[stock_comments['date'] == target_date]
        if not target_rows.empty:
            # 取第一个匹配的行
            comment_idx = target_rows.index[0]
            tone_matches.append({
                'comment_index': comment_idx,
                'stock_code_6digit': stock_code_6digit,  # 6位代码，用于匹配
                'stock_code_full': stock_code_full,      # 完整代码，用于输出
                'stock_name': stock_name,
                'target_date': target_date,
                'annual_tone': annual_tone,
                'report_date': report_date
            })
            print(f"  匹配: {report_date}->{target_date}, 年报语调={annual_tone}")
        else:
            print(f"   股票{stock_code_6digit}在{target_date}没有评论数据")
    else:
        print(f"   股票{stock_code_6digit}在{report_date}之后没有交易日")

print(f"\n成功匹配: {len(tone_matches)}/{len(tone_df)} 个年报")

# 5. 创建新DataFrame（基于评论文件）
result_df = comment_df.copy()

# 6. 添加列：股票名称和年报语调
result_df['股票名称'] = ''
result_df['年报语调'] = ''

# 7. 先填充股票名称（所有行）
stock_name_map = {}
stock_fullcode_map = {}  # 6位代码 -> 完整代码映射

for idx, row in tone_df.iterrows():
    stock_code_6digit = row['股票代码_纯数字']
    stock_name = row['股票名称']
    stock_code_full = row['股票代码']
    
    stock_name_map[stock_code_6digit] = stock_name
    stock_fullcode_map[stock_code_6digit] = stock_code_full

result_df['股票名称'] = result_df['股票代码'].map(stock_name_map)

# 8. 填充年报语调（只在匹配的行）
for match in tone_matches:
    idx = match['comment_index']
    result_df.at[idx, '年报语调'] = match['annual_tone']

# 9. 关键修改：替换股票代码为完整带后缀的代码
result_df['股票代码_6位'] = result_df['股票代码']  # 保留6位代码备份
result_df['股票代码'] = result_df['股票代码'].map(stock_fullcode_map)

# 10. 重命名和调整列顺序
result_df = result_df.rename(columns={
    'date': '评论日期',
    'sentiment_score': '评论情绪指标'
})

# 调整列顺序
column_order = ['股票代码', '股票名称', '股票代码_6位', '评论日期', '评论情绪指标', '年报语调']
result_df = result_df[column_order]

# 11. 保存结果
output_file = '年报评论匹配结果.csv'
result_df.to_csv(output_file, index=False, encoding='utf-8-sig')

print(f"\n 匹配完成！保存到: {output_file}")
print(f"输出文件行数: {len(result_df)}（与评论文件相同）")

# 12. 检查结果
tone_filled = result_df[result_df['年报语调'] != ''].shape[0]
print(f"年报语调有值的行数: {tone_filled}（应该=60）")

tone_rows = result_df[result_df['年报语调'] != '']

# 14. 验证每个年报是否都有匹配
print(f"\n=== 验证 ===")
print(f"年报文件行数: {len(tone_df)}")
print(f"匹配成功数: {len(tone_matches)}")
print(f"结果文件中年报语调有值的行数: {tone_filled}")

if tone_filled == len(tone_df):
    print(" 所有60个年报语调值都已匹配！")
else:
    missing = len(tone_df) - tone_filled
    print(f" 缺少 {missing} 个年报语调值")
    
    # 找出缺失的
    filled_codes = set([match['stock_code_6digit'] for match in tone_matches])
    for idx, row in tone_df.iterrows():
        if row['股票代码_纯数字'] not in filled_codes:
            print(f"  缺失: {row['股票名称']}({row['股票代码']})")

# 15. 检查股票代码格式
print(f"\n=== 输出文件股票代码格式检查 ===")
print("输出文件列名:", list(result_df.columns))
print("\n输出文件中的股票代码示例（前10个）:")
print(result_df['股票代码'].head(10).tolist())
print("\n输出文件中的6位股票代码示例（前10个）:")
print(result_df['股票代码_6位'].head(10).tolist())





# 1. 读取两个文件
window_df = pd.read_csv('主研究窗口.csv', encoding='utf-8-sig')
stocks_df = pd.read_csv('all_stocks_data.csv', encoding='utf-8-sig')

print("=== 原始数据信息 ===")
print(f"主研究窗口: {len(window_df)} 行, {len(window_df.columns)} 列")
print(f"股票数据: {len(stocks_df)} 行, {len(stocks_df.columns)} 列")

print("\n主研究窗口列名（中文）:")
for i, col in enumerate(window_df.columns, 1):
    print(f"  {i:2d}. {col}")

print("\n股票数据列名（英文）:")
for i, col in enumerate(stocks_df.columns, 1):
    print(f"  {i:2d}. {col}")

# 2. 将股票数据列名改为中文
column_mapping = {
    'ts_code': '股票代码',
    'trade_date': '交易日期',
    'stock_return': '股票收益率',
    'market_return': '市场收益率',
    'turnover_rate': '换手率',
    'market_cap': '市值',
    'pe_ratio': '市盈率',
    'pb_ratio': '市净率',
    'volume': '成交量',
    'amount': '成交金额',
    'period': '期间'
}

# 重命名列
stocks_df = stocks_df.rename(columns=column_mapping)

print(f"\n 股票数据列名已改为中文:")
for i, col in enumerate(stocks_df.columns, 1):
    print(f"  {i:2d}. {col}")

# 3. 统一日期格式
window_df['评论日期'] = pd.to_datetime(window_df['评论日期']).dt.date
stocks_df['交易日期'] = pd.to_datetime(stocks_df['交易日期']).dt.date

print(f"\n日期格式统一完成:")
print(f"研究窗口日期类型: {type(window_df['评论日期'].iloc[0])}")
print(f"股票数据日期类型: {type(stocks_df['交易日期'].iloc[0])}")

# 4. 统一股票代码格式（如果格式不一致）
# 检查股票代码格式
print(f"\n=== 股票代码格式检查 ===")
print("研究窗口股票代码示例（前5个）:")
print(window_df['股票代码'].head().tolist())

print("\n股票数据股票代码示例（前5个）:")
print(stocks_df['股票代码'].head().tolist())

# 如果股票代码格式不一致，统一为小写或大写
stocks_df['股票代码'] = stocks_df['股票代码'].str.upper()
window_df['股票代码'] = window_df['股票代码'].str.upper()

# 5. 合并数据（只保留在研究窗口中的股票和日期）
print(f"\n=== 开始合并数据 ===")

# 获取研究窗口中的所有股票代码和日期组合
window_combinations = set(zip(window_df['股票代码'], window_df['评论日期']))

print(f"研究窗口中有 {len(window_combinations)} 个唯一的股票-日期组合")

# 筛选股票数据：只保留在研究窗口中的股票和日期
merged_data = []

for idx, row in stocks_df.iterrows():
    stock_code = row['股票代码']
    trade_date = row['交易日期']
    
    if (stock_code, trade_date) in window_combinations:
        merged_data.append(row)

# 创建合并后的DataFrame
if merged_data:
    merged_df = pd.DataFrame(merged_data)
    
    print(f"\n 合并完成！")
    print(f"筛选后数据行数: {len(merged_df)}")
    print(f"筛选比例: {len(merged_df)/len(stocks_df)*100:.1f}%")
    
    # 6. 将研究窗口的其他信息合并进来
    # 需要合并的列：窗口位置、是否事发日、评论情绪指标、年报语调
    window_info = window_df[['股票代码', '评论日期', '窗口位置', '是否事发日', '评论情绪指标', '年报语调']].copy()
    window_info = window_info.rename(columns={'评论日期': '交易日期'})
    
    # 合并
    final_df = pd.merge(
        merged_df,
        window_info,
        on=['股票代码', '交易日期'],
        how='left'
    )
    
    print(f"\n合并后数据行数: {len(final_df)}")
    
    # 7. 调整列顺序
    column_order = [
        '股票代码', '股票名称', '交易日期', '窗口位置', '是否事发日',
        '评论情绪指标', '年报语调',
        '股票收益率', '市场收益率', '换手率', '市值',
        '市盈率', '市净率', '成交量', '成交金额', '期间'
    ]
    
    # 只保留存在的列
    column_order = [col for col in column_order if col in final_df.columns]
    final_df = final_df[column_order]
    
    # 8. 保存结果
    output_file = '研究窗口股票数据.csv'
    final_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\n 保存到: {output_file}")
    print(f"最终文件列名 ({len(final_df.columns)}列):")
    for i, col in enumerate(final_df.columns, 1):
        print(f"  {i:2d}. {col}")
    
    # 9. 显示统计信息
    print(f"\n 统计信息:")
    print(f"总行数: {len(final_df)}")
    print(f"唯一股票数: {final_df['股票代码'].nunique()}")
    print(f"日期范围: {final_df['交易日期'].min()} 到 {final_df['交易日期'].max()}")
    
    # 窗口位置分布
    print(f"\n窗口位置分布:")
    if '窗口位置' in final_df.columns:
        position_counts = final_df['窗口位置'].value_counts().sort_index()
        for pos in sorted(position_counts.index):
            count = position_counts[pos]
            print(f"  位置{pos:2d}: {count:3d}行")
    
    #  检查缺失值
    print(f"\n 缺失值检查:")
    missing_info = final_df.isnull().sum()
    missing_cols = missing_info[missing_info > 0]
    if len(missing_cols) > 0:
        print("有以下列存在缺失值:")
        for col, count in missing_cols.items():
            print(f"  {col}: {count}个缺失值 ({count/len(final_df)*100:.1f}%)")
    else:
        print(" 无缺失值")
        
else:
    print(" 没有找到匹配的数据")

print(f"\n处理完成！")










# 1. 读取文件
df = pd.read_csv('研究窗口股票数据.csv', encoding='utf-8-sig')
print(f"读取文件: {len(df)} 行")
print(f"原始列名: {list(df.columns)}")

# 2. 检查是否已经有超额收益率列，如果有先删除
if '超额收益率' in df.columns:
    print(f"⚠ 发现已有的'超额收益率'列，先删除")
    df = df.drop(columns=['超额收益率'])

# 3. 检查是否有需要的列
required_columns = ['股票收益率', '市场收益率']
missing_columns = [col for col in required_columns if col not in df.columns]

if missing_columns:
    print(f" 缺少必要列: {missing_columns}")
    print("请检查文件列名:")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i:2d}. {col}")
    exit()

# 4. 计算超额收益率（保留4位小数）
print(f"\n计算超额收益率...")
df['超额收益率'] = (df['股票收益率'] - df['市场收益率']).round(4)

# 显示计算示例
print(f"超额收益率计算示例（前5行）:")
for i in range(min(5, len(df))):
    stock_return = df.iloc[i]['股票收益率']
    market_return = df.iloc[i]['市场收益率']
    excess_return = df.iloc[i]['超额收益率']
    print(f"  第{i+1}行: {stock_return:.4f} - {market_return:.4f} = {excess_return:.4f}")

# 5. 将新列插入到'市场收益率'后面
columns = list(df.columns)
# 找到'市场收益率'的位置
market_return_idx = columns.index('市场收益率')
# 删除可能重复的'超额收益率'（如果已经存在）
if '超额收益率' in columns:
    columns.remove('超额收益率')
# 将'超额收益率'插入到'市场收益率'后面
columns.insert(market_return_idx + 1, '超额收益率')
# 重新排列列
df = df[columns]

# 6. 覆盖保存原文件
df.to_csv('研究窗口股票数据.csv', index=False, encoding='utf-8-sig')

print(f"\n 计算完成！")
print(f"新增列: 超额收益率")
print(f"总列数: {len(df.columns)}")

# 7. 显示统计信息
print(f"\n 超额收益率统计:")
print(f"平均值: {df['超额收益率'].mean():.4f}")
print(f"最小值: {df['超额收益率'].min():.4f}")
print(f"最大值: {df['超额收益率'].max():.4f}")
print(f"标准差: {df['超额收益率'].std():.4f}")

# 8. 检查是否有重复列
print(f"\n 检查重复列:")
column_counts = {}
for col in df.columns:
    column_counts[col] = column_counts.get(col, 0) + 1

duplicate_columns = [col for col, count in column_counts.items() if count > 1]
if duplicate_columns:
    print(f" 发现重复列: {duplicate_columns}")
else:
    print(f" 无重复列")

# 9. 显示最终列名
print(f"\n最终列名（共{len(df.columns)}列）:")
for i, col in enumerate(df.columns, 1):
    print(f"  {i:2d}. {col}")

print(f"\n 处理完成！已直接更新'研究窗口股票数据.csv'文件")
